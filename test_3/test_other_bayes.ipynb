{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpU8R8oXfbvB"
   },
   "outputs": [],
   "source": [
    "#imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import json \n",
    "\n",
    "import xgboost\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzdqzGlefi_v"
   },
   "outputs": [],
   "source": [
    "PREP_DATA_PATH = \"./drive/My Drive/НИР/data/prepared_facebook_data.csv\"\n",
    "data=pd.read_csv(PREP_DATA_PATH)\n",
    "\n",
    "RES_SAVE_DIR = \"./drive/My Drive/НИР/data/results/test 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6MDfaSPbflAf",
    "outputId": "6dda2f75-78d9-4424-952a-4a7977f20dcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSPTZzkYfnUO"
   },
   "outputs": [],
   "source": [
    "# get some data\n",
    "X, y = data.iloc[:,:-1].values, data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7B7zYvI0fpC2"
   },
   "outputs": [],
   "source": [
    "dtrain = xgboost.DMatrix(X, label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfcRDd3T-4IF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DkcIpWyR-4ap"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/nanomathias/bayesian-optimization-of-xgboost-lb-0-9769 \n",
    "# http://krasserm.github.io/2018/03/21/bayesian-optimization/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "PaNALkBNbcFW",
    "outputId": "5128ca9c-36da-41d9-b893-bc4dc04bc6d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-optimize\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/87/310b52debfbc0cb79764e5770fa3f5c18f6f0754809ea9e2fc185e1b67d3/scikit_optimize-0.7.4-py2.py3-none-any.whl (80kB)\n",
      "\r",
      "\u001b[K     |████                            | 10kB 19.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 20kB 1.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 30kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 40kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 51kB 2.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 61kB 2.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 71kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 81kB 2.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.4)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-20.4.0 scikit-optimize-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9LMOX1U-4Tx"
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Space, Integer\n",
    "\n",
    "bayes_cv_opt = BayesSearchCV(\n",
    "    estimator = xgboost.XGBRegressor(\n",
    "      tree_method = \"gpu_hist\", \n",
    "      gpu_id = 0, \n",
    "      verbosity = 0\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'min_child_weight': Integer(1, 10),\n",
    "        'max_depth': Integer(3, 10),\n",
    "        'subsample': Real(0.5, 0.9, 'uniform'),\n",
    "        'colsample_bytree': Real(0.5, 0.9, 'uniform'),\n",
    "        'reg_lambda': Real(0.0, 1.0, 'uniform'),\n",
    "        'reg_alpha': Real(0.0, 1.0, 'uniform'),        \n",
    "    },    \n",
    "    scoring = 'r2',\n",
    "    cv = 5,\n",
    "    n_iter = 729,\n",
    "    iid=False, \n",
    "    optimizer_kwargs={\n",
    "        \"acq_func\": \"EI\"\n",
    "        }\n",
    ")\n",
    "#print(bayes_cv_opt.total_iterations)\n",
    "\n",
    "# callback handler\n",
    "\n",
    "def on_step(optim_result):\n",
    "    score = bayes_cv_opt.best_score_\n",
    "    print(\"Best score: %s\" % score)\n",
    "    print(\"Best iteration index \", bayes_cv_opt.best_index_)\n",
    "    #if score >= 0.98:\n",
    "    #    print('Interrupting!')\n",
    "    #    return True\n",
    "\n",
    "bayes_cv_opt.fit(X, y, callback=on_step)\n",
    "\n",
    "print(\"val. score: %s\" % bayes_cv_opt.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILPpdwphh2VY"
   },
   "outputs": [],
   "source": [
    "# n_initial_points int, default=10 \n",
    "#  skopt.space.Space(\n",
    "# acq_func string, default=`”gp_hedge”` \"EI\" for negative expected improvement.\n",
    "# https://scikit-optimize.github.io/stable/modules/generated/skopt.Optimizer.html#skopt.Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thmzZYinfqlS"
   },
   "outputs": [],
   "source": [
    "#gpyopt:\n",
    "\"\"\"\n",
    "#!pip install gpyopt\n",
    "#from GPyOpt.methods import BayesianOptimization\n",
    "\n",
    "\n",
    "def my_r2_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'r2', r2_score(labels, preds)\n",
    "\n",
    "def bayes_opt_tune_xgb(para):\n",
    "  para = para[0]\n",
    "  params = {\n",
    "      \"tree_method\": \"gpu_hist\", \n",
    "      \"gpu_id\": 0, \n",
    "      \"verbosity\": 0,\n",
    "      \"max_depth\": int(round(para[0])),\n",
    "      \"min_child_weight\": int(round(para[1])),\n",
    "      \"alpha\": para[2],\n",
    "      \"lambda\": para[3],\n",
    "      \"subsample\": para[4],\n",
    "      \"colsample_bytree\": para[5]\n",
    "      }\n",
    "    #Cross validating with the specified parameters in 5 folds\n",
    "  cv_result = xgboost.cv(params, dtrain, nfold=5, feval=my_r2_score,  maximize=True)\n",
    "  gpyopt_output.append(\n",
    "        [\n",
    "         cv_result['test-r2-mean'].iloc[-1],\n",
    "         params[\"max_depth\"], params[\"min_child_weight\"], \n",
    "         params[\"alpha\"], params[\"lambda\"], \n",
    "         params[\"subsample\"], params[\"colsample_bytree\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  return cv_result['test-r2-mean'].iloc[-1]\n",
    "\n",
    "\n",
    "gpyopt_output = []\n",
    "gpy_importance = pd.DataFrame()\n",
    "bds = [ {'name': 'max_depth', 'type': 'discrete', 'domain': (3, 10)},\n",
    "        {'name': 'min_child_weight', 'type': 'discrete', 'domain': (1, 10)},\n",
    "        {'name': 'alpha', 'type': 'continuous', 'domain': (0, 1)},\n",
    "        {'name': 'lambda', 'type': 'continuous', 'domain': (0, 1)},\n",
    "        {'name': 'subsample', 'type': 'continuous', 'domain': (0.5, 0.9)},\n",
    "        {'name': 'colsample_bytree', 'type': 'continuous', 'domain': (0.5, 0.9)}\n",
    "      ]\n",
    "optimizer = BayesianOptimization(f=bayes_opt_tune_xgb, \n",
    "                                 domain=bds,\n",
    "                                 model_type='GP',\n",
    "                                 optimize_restarts = 72,\n",
    "                                 initial_design_numdata = 10,\n",
    "                                 acquisition_type ='EI',\n",
    "                                 maximize=True)\n",
    "\n",
    "optimizer.run_optimization(max_iter=719)\n",
    "results = pd.DataFrame(gpyopt_output)\n",
    "print(results.max(axis = 0))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLOiHOYToTWL"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# https://hyperopt.github.io/hyperopt/\n",
    "!pip install hyperopt\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "from hyperopt import hp\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# XGB parameters\n",
    "xgb_reg_params = {\n",
    "    \"tree_method\": \"gpu_hist\", \n",
    "    \"gpu_id\": 0, \n",
    "    \"verbosity\": 0,\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(3, 10, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 10, 1, dtype=int)),\n",
    "    'alpha': hp.uniform('alpha', 0.0, 1),\n",
    "    'lambda': hp.uniform('lambda', 0.0, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.9),\n",
    "    'subsample':        hp.uniform('subsample', 0.5, 0.9),\n",
    "    \n",
    "}\n",
    "\n",
    "xgb_para = dict()\n",
    "xgb_para['reg_params'] = xgb_reg_params\n",
    "\n",
    "def my_r2_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'r2', r2_score(labels, preds)\n",
    "\n",
    "class HPOpt(object):\n",
    "\n",
    "    def __init__(self, dtrain):\n",
    "        self.dtrain = dtrain\n",
    "\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def bayes_opt_tune_xgb(self, para):\n",
    "        cv_result = xgboost.cv(params = para['reg_params'], \n",
    "                               dtrain = self.dtrain, \n",
    "                               nfold=5, feval=my_r2_score,  maximize=True)\n",
    "        loss = cv_result = 1 - cv_result['test-r2-mean'].iloc[-1]\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "obj = HPOpt(dtrain)\n",
    "trials=Trials()\n",
    "# algo=tpe.suggest 0.35029\n",
    "xgb_opt = obj.process(fn_name='bayes_opt_tune_xgb', space=xgb_para, trials=trials, algo=tpe.suggest, max_evals=729)\n",
    "\n",
    "print(xgb_opt)\n",
    "print (1-min(trials.losses()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szSHHC4o4KPq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "test_other_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
