{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "prepare_RSgroups = False #надо ли объединить группы в один файл\n",
    "prepare_BOgroups = False\n",
    "\n",
    "# dataset_name = 'prepared_facebook_data'\n",
    "# folder_name = 'facebook_comm_vol'\n",
    "# dataset_name ='house_prices'\n",
    "# folder_name = 'boston_house_prices'\n",
    "# dataset_name = 'physics'\n",
    "# folder_name = 'physics'\n",
    "dataset_name = 'energy_consumption'\n",
    "folder_name = 'energy_consumption'\n",
    "# dataset_name = 'quote'\n",
    "# folder_name = 'quote'\n",
    "\n",
    "DIR_WITH_FILES = '../other_data_experiments/{}/first experiment/'.format(folder_name)\n",
    "DIR_WITH_BO_FILES =  '../other_data_experiments/{}/third experiment/groups/'.format(folder_name)\n",
    "\n",
    "DIR_TO_SAVE_RES = DIR_WITH_FILES\n",
    "DIR_TO_SAVE_RES = DIR_WITH_BO_FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare_RSgroups:\n",
    "    pathname = \"res_rand_group\"\n",
    "elif prepare_BOgroups:\n",
    "    pathname = \"res_BO_group\"\n",
    "else:\n",
    "    pathname = None\n",
    "    \n",
    "if pathname:\n",
    "    for i in range(1,11):\n",
    "        try:\n",
    "            part_1 = pd.read_csv(DIR_TO_SAVE_RES+\\\n",
    "                                 \"{}1_{}_{}.csv\".format(pathname, dataset_name, i))\n",
    "            part_2 = pd.read_csv(DIR_TO_SAVE_RES+\\\n",
    "                                 \"{}2_{}_{}.csv\".format(pathname, dataset_name, i))\n",
    "            part_3 = pd.read_csv(DIR_TO_SAVE_RES+\\\n",
    "                                 \"{}3_{}_{}.csv\".format(pathname, dataset_name, i))\n",
    "            full = pd.concat([part_1, part_2, part_3], sort = False)\n",
    "            full['run_number']=i\n",
    "            print(full.shape)\n",
    "            full.to_csv(DIR_TO_SAVE_RES+\"{}s_{}_{}.csv\".format(pathname, dataset_name, i), index=False)\n",
    "        except:\n",
    "            print(f\"{i} is NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RS_time = np.array([])\n",
    "print(np.mean(RS_time))\n",
    "print(np.std(RS_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_1_time = np.array([])\n",
    "group_2_time = np.array([])\n",
    "group_3_time = np.array([])\n",
    "\n",
    "sum_arr=np.sum([group_1_time, group_2_time, group_3_time], axis = 0)\n",
    "\n",
    "\n",
    "for arr in [group_1_time, group_2_time, group_3_time, sum_arr]:\n",
    "    print(np.mean(arr))\n",
    "    print(np.std(arr))\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_best_params_with_stop(df, stop_iter_num, left_iter_num, right_iter_num):\n",
    "    best_params = {}\n",
    "    stop_iter_nums = {}\n",
    "    best_score = {}\n",
    "\n",
    "    tmp_df = df.loc[(df['iter_num'] >= left_iter_num) & (df['iter_num'] <= right_iter_num)].copy() #take group\n",
    "    for i in tmp_df.run_number.unique(): \n",
    "      tmp_df_i = tmp_df.loc[tmp_df.run_number==i] #take run\n",
    "      #cut iterations:\n",
    "      tmp_df_i_copy = tmp_df_i.copy()\n",
    "      tmp_df_i_copy.loc[:, \"mean_test_score\"] = tmp_df_i_copy.loc[\n",
    "          :, \"mean_test_score\"].cummax()      \n",
    "\n",
    "      try:\n",
    "          curr_max=tmp_df_i_copy.groupby(\"mean_test_score\").count().reset_index().sort_values(by = \"mean_test_score\")\n",
    "          max_score = curr_max.loc[curr_max[\"mean_test_score\"]>=stop_iter_num].index[0] #get first interval with iter_amount more than stop_iter_num\n",
    "      except:\n",
    "          max_score = tmp_df_i_copy.mean_test_score.max()\n",
    "\n",
    "      tmp_stop = tmp_df_i.loc[tmp_df_i[\"mean_test_score\"]==max_score].sort_values(by=\"iter_num\").iloc[0]#get first element with best_score\n",
    "    \n",
    "      best_params[i] = tmp_stop['params']\n",
    "      #best_score[i] = tmp_stop['mean_test_score']\n",
    "\n",
    "      last_iter_num = tmp_stop['iter_num'] + stop_iter_num - 1\n",
    "      if last_iter_num > right_iter_num:\n",
    "          last_iter_num = right_iter_num\n",
    "\n",
    "      stop_iter_nums[i] = last_iter_num\n",
    "    return best_params, stop_iter_nums#, best_score       \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is OK\n",
      "2 is OK\n",
      "3 is OK\n",
      "4 is OK\n",
      "5 is OK\n",
      "6 is OK\n",
      "7 is OK\n",
      "8 is OK\n",
      "9 is OK\n",
      "10 is OK\n"
     ]
    }
   ],
   "source": [
    "group_df = pd.DataFrame([])\n",
    "\n",
    "pathname =  \"res_BO_group\" #\"res_BO_group\" res_rand_group\n",
    "for i in range(1, 11):\n",
    "    try:\n",
    "        df = pd.read_csv(DIR_TO_SAVE_RES+\"{}s_{}_{}.csv\".format(pathname, dataset_name, i))    \n",
    "        df['iter_num'] = range(1, df.shape[0]+1)\n",
    "        group_df = pd.concat([group_df, df], sort = False)\n",
    "        print(f\"{i} is OK\")\n",
    "    except:\n",
    "        print(f\"{i} is NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_iter_num = 25\n",
    "# pathname =  \"res_rand_group\" \n",
    "best_params_first_group, first_stop_iter_nums = group_best_params_with_stop(\n",
    "    group_df, stop_iter_num = stop_iter_num,\n",
    "    left_iter_num=1, right_iter_num=243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\",\n",
       " 2: \"OrderedDict([('max_depth', 3), ('min_child_weight', 2)])\",\n",
       " 3: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\",\n",
       " 4: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\",\n",
       " 5: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\",\n",
       " 6: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\",\n",
       " 7: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\",\n",
       " 8: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\",\n",
       " 9: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\",\n",
       " 1: \"OrderedDict([('max_depth', 3), ('min_child_weight', 1)])\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params_first_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 41, 2: 36, 3: 50, 4: 47, 5: 41, 6: 38, 7: 43, 8: 45, 9: 48, 1: 38}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_stop_iter_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_iter_num = 25\n",
    "\n",
    "best_params_second_group={}\n",
    "second_stop_iter_nums={}\n",
    "\n",
    "full_datasets = [2]\n",
    "for i in full_datasets:\n",
    "    group_df = pd.read_csv(DIR_TO_SAVE_RES+\"{}s_{}_{}.csv\".format(pathname, dataset_name, i))\n",
    "    group_df['iter_num'] = range(1, group_df.shape[0]+1)\n",
    "    first_group_stop_iters = 243\n",
    "    left_iter_num = first_group_stop_iters+1\n",
    "    right_iter_num =left_iter_num + int(round((729 - first_group_stop_iters)/2))\n",
    "\n",
    "    best_params_second_group_tmp, second_stop_iter_nums_tmp = group_best_params_with_stop(\n",
    "        group_df, stop_iter_num = stop_iter_num,\n",
    "        left_iter_num=left_iter_num, right_iter_num=right_iter_num)\n",
    "    best_params_second_group.update(best_params_second_group_tmp)\n",
    "    second_stop_iter_nums.update(second_stop_iter_nums_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_params_second_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_stop_iter_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_datasets = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# код склейки для 3 группы со второй, если первая группа была полной \n",
    "\n",
    "DIR_TO_SAVE_RES_SEC= '../other_data_experiments/{}/second experiment/'.format(folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for params_set_num in full_datasets:\n",
    "    res_rand_2 = pd.read_csv(\n",
    "        DIR_TO_SAVE_RES+'res_rand_group1_{}_{}.csv'.format(dataset_name, params_set_num))\n",
    "    \n",
    "    res_rand_3 = pd.read_csv(\n",
    "        DIR_TO_SAVE_RES_SEC+'GR_S_3_group_with_{}_{}_{}.csv'.format(stop_iter_num, params_set_num, dataset_name))\n",
    "    \n",
    "    best_params_third_group, third_stop_iter_nums = group_best_params_with_stop(res_rand_3, \n",
    "                                                          stop_iter_num = stop_iter_num, \n",
    "                                                          left_iter_num=second_stop_iter_nums[params_set_num]+1, \n",
    "                                                          right_iter_num=729)\n",
    "    \n",
    "    res_rand_3=res_rand_3.loc[(res_rand_3['run_number']==params_set_num) & \\\n",
    "                            (res_rand_3['iter_num']<=int(third_stop_iter_nums[params_set_num]))]\n",
    "\n",
    "    \n",
    "    res=pd.concat([res_rand_2,res_rand_3], sort=False)\n",
    "\n",
    "    sec_idxs = res.loc[res['experiment_name']=='random search for 2 group','iter_num'].values\n",
    "    third_idxs = res.loc[res['experiment_name']=='random search for 3 group','iter_num'].values\n",
    "    intersection = np.intersect1d(third_idxs, sec_idxs)\n",
    "\n",
    "    res = res.loc[~((res['experiment_name']=='random search for 2 group') & (res['iter_num'].isin(intersection)))]\n",
    "\n",
    "    res.to_csv(DIR_TO_SAVE_RES_SEC+'GR_S_2_and_3_groups_with_{}_{}_{}.csv'.format(stop_iter_num, params_set_num, dataset_name),\n",
    "               index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir = '../other_data_experiments/energy_consumption/fourth experiment/stop25/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{0: \"OrderedDict([('reg_alpha', 0.0006314604698443028), ('reg_lambda', 0.08915747566387168)])\"}\n",
      "{0: 262}\n",
      "1\n",
      "{1: \"OrderedDict([('reg_alpha', 0.0018765561834858118), ('reg_lambda', 0.08701689706660977)])\"}\n",
      "{1: 301}\n",
      "3\n",
      "{3: \"OrderedDict([('reg_alpha', 0.02627876299749022), ('reg_lambda', 0.1193524320564491)])\"}\n",
      "{3: 267}\n",
      "4\n",
      "{4: \"OrderedDict([('reg_alpha', 0.005412441623557474), ('reg_lambda', 0.10391679569619475)])\"}\n",
      "{4: 299}\n",
      "7\n",
      "{7: \"OrderedDict([('reg_alpha', 0.9983049091157783), ('reg_lambda', 0.10914033436242035)])\"}\n",
      "{7: 231}\n",
      "9\n",
      "{9: \"OrderedDict([('reg_alpha', 0.007644247335100831), ('reg_lambda', 0.10259659858566941)])\"}\n",
      "{9: 345}\n"
     ]
    }
   ],
   "source": [
    "stop_iter_num = 25\n",
    "for i in [0, 1, 3, 4, 7, 9]:\n",
    "    group_df = pd.read_csv(tmp_dir + f'GRBO_S_2_group_with_25_{i}_energy_consumption.csv')\n",
    "\n",
    "    \n",
    "\n",
    "    first_group_stop_iters = first_stop_iter_nums[i]\n",
    "    left_iter_num = first_group_stop_iters+1\n",
    "    right_iter_num =left_iter_num + int(round((729 - first_group_stop_iters)/2))\n",
    "\n",
    "    best_params_second_group, second_stop_iter_nums = group_best_params_with_stop(\n",
    "        group_df, stop_iter_num = stop_iter_num,\n",
    "        left_iter_num=left_iter_num, right_iter_num=right_iter_num)\n",
    "    \n",
    "    print(i)\n",
    "    print(best_params_second_group)\n",
    "    print(second_stop_iter_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
